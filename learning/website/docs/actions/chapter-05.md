---
sidebar_position: 6
title: ç¬¬äº”ç« ï¼šKVç¼“å­˜ç®¡ç†ä¸Radixæ ‘ä¼˜åŒ–
description: ç†è§£ç¼“å­˜å¤ç”¨ã€Radixæ ‘å’Œå†…å­˜ç®¡ç†
---

# ç¬¬äº”ç« ï¼šKVç¼“å­˜ç®¡ç†ä¸Radixæ ‘ä¼˜åŒ–

## æœ¬ç« å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å°†äº†è§£ï¼š
- KVç¼“å­˜çš„æ ¸å¿ƒæ¶æ„å’Œå†…å­˜ç®¡ç†æœºåˆ¶
- Radixæ ‘ç¼“å­˜å¤ç”¨ç®—æ³•çš„å®ç°åŸç†
- é«˜æ€§èƒ½ç¼“å­˜å­˜å‚¨å’Œç´¢å¼•æ“ä½œ
- ç¼“å­˜æ·˜æ±°ç­–ç•¥å’Œå†…å­˜å¹³è¡¡ç®¡ç†
- ä¸åŒç¼“å­˜ç­–ç•¥çš„æ€§èƒ½å¯¹æ¯”

## æ ¸å¿ƒæ¦‚å¿µé€ŸæŸ¥è¡¨

| æœ¯è¯­ | è‹±æ–‡ | è§£é‡Š |
|------|------|------|
| **KV ç¼“å­˜** | KV Cache | å­˜å‚¨ Transformer æ¨¡å‹ä¸­ Attention å±‚çš„ Key å’Œ Value çŸ©é˜µï¼Œé¿å…é‡å¤è®¡ç®—ã€‚ |
| **Radix æ ‘** | Radix Tree | ä¸€ç§å‹ç¼©å‰ç¼€æ ‘ï¼ŒMini-SGLang ç”¨å®ƒæ¥ç®¡ç† KV Cacheï¼Œæ”¯æŒé«˜æ•ˆçš„å‰ç¼€åŒ¹é…å’Œå¤ç”¨ã€‚ |
| **PagedAttention** | PagedAttention | ä¸€ç§å—æ“ä½œç³»ç»Ÿè™šæ‹Ÿå†…å­˜å¯å‘çš„æ˜¾å­˜ç®¡ç†æŠ€æœ¯ï¼Œå°† KV Cache åˆ†æˆå›ºå®šå¤§å°çš„å—ï¼ˆPageï¼‰ï¼Œå…è®¸éè¿ç»­å­˜å‚¨ï¼Œå½»åº•è§£å†³äº†æ˜¾å­˜ç¢ç‰‡é—®é¢˜ã€‚ |
| **LRU** | Least Recently Used | æœ€è¿‘æœ€å°‘ä½¿ç”¨æ·˜æ±°ç®—æ³•ï¼Œå½“ç¼“å­˜ç©ºé—´ä¸è¶³æ—¶ï¼Œä¼˜å…ˆæ·˜æ±°æœ€ä¹…æœªè¢«è®¿é—®çš„æ•°æ®ã€‚ |
| **å¼•ç”¨è®¡æ•°** | Reference Counting | è®°å½•æ¯ä¸ªç¼“å­˜å—è¢«å¼•ç”¨çš„æ¬¡æ•°ï¼Œåªæœ‰å½“å¼•ç”¨è®¡æ•°ä¸º 0 æ—¶ï¼Œè¯¥å—æ‰èƒ½è¢«å®‰å…¨å›æ”¶ã€‚ |

## èƒŒæ™¯çŸ¥è¯†

### LLMæ¨ç†ä¸­çš„KVç¼“å­˜æŒ‘æˆ˜

åœ¨å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä¸­ï¼ŒKVç¼“å­˜ç®¡ç†é¢ä¸´ä»¥ä¸‹å…³é”®æŒ‘æˆ˜ï¼š

1. **å†…å­˜æ¶ˆè€—å·¨å¤§**ï¼šKVç¼“å­˜å ç”¨å¤§é‡æ˜¾å­˜ï¼Œç‰¹åˆ«æ˜¯é•¿åºåˆ—æ¨ç†
2. **ç¼“å­˜å¤ç”¨å›°éš¾**ï¼šå¦‚ä½•é«˜æ•ˆå¤ç”¨å…±äº«å‰ç¼€çš„ç¼“å­˜
3. **å†…å­˜ç¢ç‰‡åŒ–**ï¼šåŠ¨æ€åˆ†é…å¯¼è‡´å†…å­˜åˆ©ç”¨ç‡ä¸‹é™
4. **å¹¶å‘è®¿é—®å†²çª**ï¼šå¤šè¯·æ±‚åŒæ—¶è®¿é—®ç¼“å­˜çš„å®‰å…¨æ€§é—®é¢˜
5. **æ·˜æ±°ç­–ç•¥é€‰æ‹©**ï¼šå¦‚ä½•åœ¨æœ‰é™å†…å­˜ä¸­ç®¡ç†å¤§é‡ç¼“å­˜æ•°æ®

### å…³é”®æŠ€æœ¯æ¦‚å¿µ

- **KVç¼“å­˜ï¼ˆKey-Value Cacheï¼‰**ï¼šå­˜å‚¨æ³¨æ„åŠ›è®¡ç®—ä¸­çš„é”®å€¼å¯¹
- **Radixæ ‘ï¼ˆåŸºæ•°æ ‘ï¼‰**ï¼šåŸºäºå‰ç¼€çš„æ ‘å½¢æ•°æ®ç»“æ„ï¼Œæ”¯æŒé«˜æ•ˆå‰ç¼€åŒ¹é…
- **ç¼“å­˜å¤ç”¨**ï¼šå…±äº«å‰ç¼€çš„è¯·æ±‚å¯ä»¥å¤ç”¨å·²è®¡ç®—çš„KVç¼“å­˜
- **å†…å­˜æ± ç®¡ç†**ï¼šé¢„åˆ†é…å†…å­˜å—å‡å°‘åŠ¨æ€åˆ†é…å¼€é”€
- **LRUæ·˜æ±°**ï¼šæœ€è¿‘æœ€å°‘ä½¿ç”¨ç­–ç•¥ç®¡ç†ç¼“å­˜ç”Ÿå‘½å‘¨æœŸ

### PagedAttention ä¸å†…å­˜ç®¡ç†

ä¼ ç»Ÿçš„ KV Cache åˆ†é…æ–¹å¼è¦æ±‚æ˜¾å­˜è¿ç»­ï¼Œè¿™å¯¼è‡´äº†ä¸¥é‡çš„å†…å­˜ç¢ç‰‡å’Œæµªè´¹ï¼ˆç±»ä¼¼äºæ“ä½œç³»ç»Ÿä¸­çš„å¤–éƒ¨ç¢ç‰‡ï¼‰ã€‚
- **PagedAttention** çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°† KV Cache è§†ä¸ºè™šæ‹Ÿå†…å­˜ï¼Œå°†æ˜¾å­˜åˆ’åˆ†ä¸ºå›ºå®šå¤§å°çš„å—ï¼ˆBlock/Pageï¼‰ã€‚
- **ä¼˜åŠ¿**ï¼š
    1.  **æ¶ˆé™¤ç¢ç‰‡**ï¼šå…è®¸ KV Cache åœ¨ç‰©ç†æ˜¾å­˜ä¸Šä¸è¿ç»­ã€‚
    2.  **çµæ´»å…±äº«**ï¼šä¸åŒçš„è¯·æ±‚å¯ä»¥å…±äº«åŒä¸€ä¸ªç‰©ç†å—ï¼ˆä¾‹å¦‚ System Promptï¼‰ã€‚
    3.  **åŠ¨æ€åˆ†é…**ï¼šæŒ‰éœ€åˆ†é…å—ï¼Œæ— éœ€é¢„å…ˆåˆ†é…æœ€å¤§é•¿åº¦ã€‚

Mini-SGLang çš„ `MHAKVCache` æ”¯æŒ `PageFirst` å¸ƒå±€ï¼Œæ­£æ˜¯ä¸ºäº†é…åˆè¿™ç§åˆ†é¡µç®¡ç†æœºåˆ¶ã€‚

## KVç¼“å­˜ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„æ¦‚è§ˆ

```mermaid
graph TB
    A[KVç¼“å­˜ç³»ç»Ÿ] --> B[ç¼“å­˜ç®¡ç†å™¨]
    A --> C[ç¼“å­˜å­˜å‚¨]
    A --> D[ç´¢å¼•ç®¡ç†]
    A --> E[å†…å­˜ç®¡ç†]
    
    B --> B1[RadixCacheManager]
    B --> B2[NaiveCacheManager]
    B --> B3[CacheHandle]
    
    C --> C1[MHAKVCache]
    C --> C2[å­˜å‚¨å¸ƒå±€]
    C --> C3[å†…æ ¸æ“ä½œ]
    
    D --> D1[é¡µé¢è¡¨]
    D --> D2[ç´¢å¼•æ˜ å°„]
    D --> D3[å‰ç¼€åŒ¹é…]
    
    E --> E1[å†…å­˜åˆ†é…]
    E --> E2[ç¼“å­˜æ·˜æ±°]
    E --> E3[å¼•ç”¨è®¡æ•°]
```

### æ ¸å¿ƒç»„ä»¶å…³ç³»

```mermaid
sequenceDiagram
    participant R as è¯·æ±‚
    participant CM as ç¼“å­˜ç®¡ç†å™¨
    participant RT as Radixæ ‘
    participant KC as KVç¼“å­˜
    participant IM as ç´¢å¼•ç®¡ç†å™¨
    
    R->>CM: è¾“å…¥åºåˆ—
    CM->>RT: å‰ç¼€åŒ¹é…
    RT->>CM: è¿”å›åŒ¹é…èŠ‚ç‚¹
    CM->>KC: é”å®šç¼“å­˜å¥æŸ„
    KC->>IM: è·å–ç¼“å­˜ä½ç½®
    IM->>KC: è¿”å›ç´¢å¼•æ˜ å°„
    KC->>R: è¿”å›ç¼“å­˜æ•°æ®
    R->>KC: å†™å…¥æ–°ç¼“å­˜
    KC->>RT: æ›´æ–°æ ‘ç»“æ„
```

## KVç¼“å­˜åŸºç¡€æ¶æ„

### 1. æŠ½è±¡æ¥å£è®¾è®¡

#### åŸºç¡€ç¼“å­˜æ¥å£

```python
class BaseKVCache(ABC):
    """KVç¼“å­˜åŸºç¡€æ¥å£"""
    
    @abstractmethod
    def k_cache(self, index: int) -> torch.Tensor: ...
    
    @abstractmethod
    def v_cache(self, index: int) -> torch.Tensor: ...
    
    @abstractmethod
    def store_kv(self, k: torch.Tensor, v: torch.Tensor, 
                 out_loc: torch.Tensor, layer_id: int) -> None: ...
```

#### ç¼“å­˜ç®¡ç†å™¨æ¥å£

```python
class BaseCacheManager(ABC):
    """ç¼“å­˜ç®¡ç†å™¨åŸºç¡€æ¥å£"""
    
    @abstractmethod
    def match_prefix(self, input_ids: torch.Tensor) -> Tuple[BaseCacheHandle, torch.Tensor]: ...
    
    @abstractmethod
    def lock_handle(self, handle: BaseCacheHandle, unlock: bool = False) -> None: ...
    
    @abstractmethod
    def insert_prefix(self, input_ids: torch.Tensor, indices: torch.Tensor) -> int: ...
    
    @abstractmethod
    def evict(self, size: int) -> torch.Tensor: ...
```

### 2. ç¼“å­˜å­˜å‚¨å®ç°

#### MHAKVCacheå¤šå¤´éƒ¨ç¼“å­˜

```python
class MHAKVCache(BaseKVCache):
    """å¤šå¤´æ³¨æ„åŠ›KVç¼“å­˜å®ç°"""
    
    def __init__(self, num_kv_heads: int, num_layers: int, head_dim: int, 
                 num_pages: int, dtype: torch.dtype, kv_layout: KVCacheLayout, 
                 device: torch.device):
        
        # æ ¹æ®å¼ é‡å¹¶è¡Œè°ƒæ•´KVå¤´æ•°
        tp_info = get_tp_info()
        local_kv_heads = divide_even(num_kv_heads, tp_info.size)
        
        # é€‰æ‹©å­˜å‚¨å¸ƒå±€
        match kv_layout:
            case KVCacheLayout.PageFirst:
                # é¡µé¢ä¼˜å…ˆå¸ƒå±€ï¼šé€‚åˆé¡µé¢ç®¡ç†
                kv_buffer = torch.empty((2, num_pages, num_layers, local_kv_heads, head_dim))
            case KVCacheLayout.LayerFirst:
                # å±‚ä¼˜å…ˆå¸ƒå±€ï¼šé€‚åˆå±‚å¹¶è¡Œ
                kv_buffer = torch.empty((2, num_layers, num_pages, local_kv_heads, head_dim))
        
        self._kv_buffer = kv_buffer.view(2, num_layers, num_pages, 1, local_kv_heads, head_dim)
        self._k_buffer = self._kv_buffer[0]  # Keyç¼“å­˜
        self._v_buffer = self._kv_buffer[1]  # Valueç¼“å­˜
```

#### å­˜å‚¨å¸ƒå±€å¯¹æ¯”

```mermaid
graph LR
    A[å­˜å‚¨å¸ƒå±€] --> B[PageFirst]
    A --> C[LayerFirst]
    
    B --> B1[é¡µé¢è¿ç»­å­˜å‚¨]
    B --> B2[é€‚åˆé¡µé¢ç®¡ç†]
    B --> B3[ç¼“å­˜å±€éƒ¨æ€§å¥½]
    
    C --> C1[å±‚è¿ç»­å­˜å‚¨]
    C --> C2[é€‚åˆå±‚å¹¶è¡Œ]
    C --> C3[è·¨é¡µé¢è®¿é—®]
```

### 3. é«˜æ€§èƒ½å­˜å‚¨å†…æ ¸

#### ç¼“å­˜å­˜å‚¨å†…æ ¸

```python
@lru_cache(maxsize=None)
def _jit_store_module(element_size: int, config: KernelConfig) -> Module:
    """JITç¼–è¯‘ç¼“å­˜å­˜å‚¨å†…æ ¸"""
    args = make_cpp_args(element_size, *config)
    return load_jit(
        "store",
        *args,
        cuda_files=["store.cu"],
        cuda_wrappers=[("launch", f"StoreKernel<{args}>::run")],
    )

def store_cache(k_cache: torch.Tensor, v_cache: torch.Tensor, 
                indices: torch.Tensor, k: torch.Tensor, v: torch.Tensor) -> None:
    """é«˜æ€§èƒ½KVç¼“å­˜å­˜å‚¨æ“ä½œ"""
    
    # å±•å¹³ç¼“å­˜ä»¥æ”¯æŒé«˜æ•ˆè®¿é—®
    num_tokens = k_cache.shape[0]
    k_cache = k_cache.view(num_tokens, -1)
    v_cache = v_cache.view(num_tokens, -1)
    
    # è®¡ç®—å…ƒç´ å¤§å°å¹¶åŠ è½½å†…æ ¸
    element_size = k_cache.shape[1] * k_cache.element_size()
    module = _jit_store_module(element_size)
    
    # æ‰§è¡Œå†…æ ¸æ“ä½œ
    module.launch(k_cache, v_cache, indices, k, v)
```

## ğŸŒ³ Radixæ ‘ç¼“å­˜ä¼˜åŒ–

### 1. Radixæ ‘æ•°æ®ç»“æ„

#### æ ‘èŠ‚ç‚¹è®¾è®¡

```python
class RadixTreeNode:
    """Radixæ ‘èŠ‚ç‚¹ï¼Œå­˜å‚¨ç¼“å­˜åºåˆ—å’Œå­èŠ‚ç‚¹æ˜ å°„"""
    
    counter: int = 0  # å…¨å±€èŠ‚ç‚¹è®¡æ•°å™¨
    
    def __init__(self, tic: int | None = None):
        self.children: Dict[int, RadixTreeNode] = {}  # å­èŠ‚ç‚¹æ˜ å°„
        self._parent: RadixTreeNode | None = None     # çˆ¶èŠ‚ç‚¹
        self.ref_count: int = 0                       # å¼•ç”¨è®¡æ•°
        self.uuid = RadixTreeNode.counter            # å”¯ä¸€æ ‡è¯†
        self.timestamp = tic or time.monotonic_ns()  # è®¿é—®æ—¶é—´æˆ³
        
        # ç¼“å­˜æ•°æ®
        self._key: torch.Tensor     # é”®åºåˆ—
        self._value: torch.Tensor   # å€¼åºåˆ—ï¼ˆç¼“å­˜ç´¢å¼•ï¼‰
        self._length: int           # åºåˆ—é•¿åº¦
```

#### æ ‘ç»“æ„ç¤ºä¾‹

```mermaid
graph TB
    R[Root Node] --> A[Token 1]
    R --> B[Token 2]
    R --> C[Token 3]
    
    A --> A1[Token 4]
    A --> A2[Token 5]
    
    A1 --> A11[Token 6]
    A1 --> A12[Token 7]
    
    B --> B1[Token 8]
    
    C --> C1[Token 9]
    C --> C2[Token 10]
    
    style R fill:#f9f
    style A11 fill:#9f9
    style A12 fill:#9f9
    style B1 fill:#9f9
    style C2 fill:#9f9
```

### 2. å‰ç¼€åŒ¹é…ç®—æ³•

#### æ ‘éå†ç®—æ³•

```python
def _walk(self, input_ids: torch.Tensor) -> Tuple[RadixTreeNode, int]:
    """éå†Radixæ ‘å¯»æ‰¾æœ€é•¿åŒ¹é…å‰ç¼€"""
    
    prefix_len = 0
    indice_len = len(input_ids)
    node = self.root_node
    tic = time.monotonic_ns()
    
    while prefix_len < indice_len:
        # è·å–å½“å‰token
        this_id = int(input_ids[prefix_len].item())
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„å­èŠ‚ç‚¹
        if this_id not in node.children:
            return node, prefix_len
        
        # ç§»åŠ¨åˆ°å­èŠ‚ç‚¹
        node = node.children[this_id]
        
        # è®¡ç®—åŒ¹é…é•¿åº¦
        match_len = node.get_match_len(input_ids[prefix_len:])
        prefix_len += match_len
        
        # å¤„ç†éƒ¨åˆ†åŒ¹é…æƒ…å†µï¼ˆéœ€è¦åˆ†å‰²èŠ‚ç‚¹ï¼‰
        if match_len != node.length:
            node = node._split_at(match_len)
            return node, prefix_len
        
        # æ›´æ–°è®¿é—®æ—¶é—´æˆ³
        node.timestamp = tic
    
    return node, prefix_len
```

#### å‰ç¼€åŒ¹é…æµç¨‹

```mermaid
sequenceDiagram
    participant C as å®¢æˆ·ç«¯
    participant RM as Radixç®¡ç†å™¨
    participant RT as Radixæ ‘
    participant KC as KVç¼“å­˜
    
    C->>RM: è¾“å…¥åºåˆ— [1,2,3,4,5]
    RM->>RT: éå†æ ‘ç»“æ„
    
    alt å®Œå…¨åŒ¹é…
        RT->>RM: è¿”å›åŒ¹é…èŠ‚ç‚¹å’Œé•¿åº¦
        RM->>KC: è·å–ç¼“å­˜ç´¢å¼•
        KC->>RM: è¿”å›ç¼“å­˜æ•°æ®
        RM->>C: è¿”å›åŒ¹é…ç»“æœ
    else éƒ¨åˆ†åŒ¹é…
        RT->>RM: è¿”å›éƒ¨åˆ†åŒ¹é…èŠ‚ç‚¹
        RM->>RT: åˆ†å‰²èŠ‚ç‚¹
        RT->>RM: è¿”å›æ–°èŠ‚ç‚¹
        RM->>KC: åˆ†é…æ–°ç¼“å­˜
        KC->>RM: è¿”å›æ–°ç´¢å¼•
        RM->>C: è¿”å›éƒ¨åˆ†åŒ¹é…ç»“æœ
    end
```

### 3. ç¼“å­˜å¤ç”¨æœºåˆ¶

#### åŒ¹é…å‰ç¼€æŸ¥æ‰¾

```python
def match_prefix(self, input_ids: torch.Tensor) -> Tuple[RadixCacheHandle, torch.Tensor]:
    """åŒ¹é…è¾“å…¥åºåˆ—çš„å‰ç¼€å¹¶è¿”å›ç¼“å­˜ç´¢å¼•"""
    
    node, prefix_len = self._walk(input_ids)
    
    # æ— åŒ¹é…æƒ…å†µ
    if prefix_len == 0:
        return RadixCacheHandle(prefix_len, node), self.empty_tensor
    
    # æ”¶é›†åŒ¹é…è·¯å¾„ä¸Šçš„æ‰€æœ‰å€¼
    value_list: List[torch.Tensor] = []
    while not node.is_root():
        value_list.append(node.value)  # ç¼“å­˜ç´¢å¼•
        node = node.parent
    
    # åè½¬å¹¶æ‹¼æ¥ç´¢å¼•åºåˆ—
    value_list.reverse()
    return RadixCacheHandle(prefix_len, node), torch.cat(value_list)
```

#### ç¼“å­˜å¤ç”¨ç¤ºä¾‹

å‡è®¾å·²æœ‰ç¼“å­˜ï¼š
- åºåˆ—A: [1,2,3] â†’ ç¼“å­˜ç´¢å¼• [100,101,102]
- åºåˆ—B: [1,2,4] â†’ ç¼“å­˜ç´¢å¼• [103,104,105]

æ–°è¯·æ±‚ï¼šåºåˆ—C: [1,2,3,5]
- åŒ¹é…å‰ç¼€: [1,2,3]ï¼ˆé•¿åº¦3ï¼‰
- å¤ç”¨ç¼“å­˜: ç´¢å¼• [100,101,102]
- æ–°å¢ç¼“å­˜: ç´¢å¼• [106]ï¼ˆå¯¹åº”token 5ï¼‰

### 4. èŠ‚ç‚¹åˆ†å‰²ç­–ç•¥

#### åŠ¨æ€èŠ‚ç‚¹åˆ†å‰²

```python
def _split_at(self, pos: int) -> RadixTreeNode:
    """åœ¨æŒ‡å®šä½ç½®åˆ†å‰²èŠ‚ç‚¹"""
    
    assert 0 < pos < self.length
    parent = self.parent
    
    # åˆ›å»ºæ–°èŠ‚ç‚¹å­˜å‚¨å‰åŠéƒ¨åˆ†
    new_node = RadixTreeNode(self.timestamp)
    new_node.set_key_value(self._key[:pos], self._value[:pos])
    new_node.set_parent(parent)
    new_node.ref_count = self.ref_count
    
    # æ›´æ–°å½“å‰èŠ‚ç‚¹ä¸ºååŠéƒ¨åˆ†
    self.set_key_value(self._key[pos:], self._value[pos:])
    self.set_parent(new_node)
    
    return new_node
```

#### èŠ‚ç‚¹åˆ†å‰²ç¤ºæ„å›¾

å½“æ’å…¥æ–°åºåˆ— `[1, 2, 5]` åˆ°å·²æœ‰èŠ‚ç‚¹ `[1, 2, 3, 4]` æ—¶ï¼Œå‘ç”Ÿåˆ†å‰²ï¼š

```mermaid
graph TB
    subgraph Before Split
        A[Parent] --> B[Node: 1, 2, 3, 4]
    end
    
    subgraph After Split
        A2[Parent] --> C[New Node: 1, 2]
        C --> D[Original Node: 3, 4]
        C --> E[New Branch: 5]
    end
```

#### åˆ†å‰²åœºæ™¯ç¤ºä¾‹

```mermaid
graph TB
    A[åŸèŠ‚ç‚¹: [1,2,3,4]] --> B[åˆ†å‰²ä½ç½®: 2]
    B --> C[æ–°èŠ‚ç‚¹: [1,2]]
    B --> D[å½“å‰èŠ‚ç‚¹: [3,4]]
    
    C --> E[å­èŠ‚ç‚¹æ˜ å°„]
    D --> F[å­èŠ‚ç‚¹æ˜ å°„]
    
    E --> E1[åŸå­èŠ‚ç‚¹]
    F --> F1[åŸå­èŠ‚ç‚¹]
```

## ğŸ”’ ç¼“å­˜ç®¡ç†æœºåˆ¶

### 1. å¼•ç”¨è®¡æ•°ç®¡ç†

#### ç¼“å­˜é”å®šæœºåˆ¶

```python
def lock_handle(self, handle: BaseCacheHandle, unlock: bool = False) -> None:
    """é”å®šæˆ–è§£é”ç¼“å­˜å¥æŸ„"""
    
    assert isinstance(handle, RadixCacheHandle)
    node = handle.node
    
    if unlock:
        # è§£é”ï¼šå‡å°‘å¼•ç”¨è®¡æ•°
        while not node.is_root():
            node = node.parent
            node.ref_count -= 1
            
            # å¼•ç”¨è®¡æ•°å½’é›¶æ—¶å˜ä¸ºå¯æ·˜æ±°
            if node.ref_count == 0:
                self.evictable_size += node.length
                self.protected_size -= node.length
    else:
        # åŠ é”ï¼šå¢åŠ å¼•ç”¨è®¡æ•°
        while not node.is_root():
            node = node.parent
            
            # å¼•ç”¨è®¡æ•°ä»0å˜ä¸º1æ—¶ä»å¯æ·˜æ±°è½¬ä¸ºå—ä¿æŠ¤
            if node.ref_count == 0:
                self.evictable_size -= node.length
                self.protected_size += node.length
            
            node.ref_count += 1
```

#### å¼•ç”¨è®¡æ•°çŠ¶æ€è½¬æ¢

```mermaid
graph LR
    A[å¼•ç”¨è®¡æ•°=0] -->|åŠ é”| B[å¼•ç”¨è®¡æ•°=1]
    B -->|è§£é”| A
    B -->|å†åŠ é”| C[å¼•ç”¨è®¡æ•°=2]
    C -->|è§£é”| B
    
    style A fill:#f99
    style B fill:#9f9
    style C fill:#9f9
```

### 2. ç¼“å­˜æ·˜æ±°ç­–ç•¥

#### LRUæ·˜æ±°ç®—æ³•

```python
def evict(self, size: int) -> torch.Tensor:
    """æ·˜æ±°æŒ‡å®šå¤§å°çš„ç¼“å­˜"""
    
    if size == 0:
        return self.empty_tensor
    
    # æ£€æŸ¥å¯æ·˜æ±°ç©ºé—´æ˜¯å¦è¶³å¤Ÿ
    assert size <= self.evictable_size, f"Cannot evict {size}, only {self.evictable_size} available"
    
    # æ”¶é›†å¯æ·˜æ±°çš„å¶å­èŠ‚ç‚¹
    leave_nodes = self._collect_leave_nodes_for_evict()
    heapq.heapify(leave_nodes)  # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæœ€å°å †ï¼‰
    
    evicted_indices: List[torch.Tensor] = []
    evicted_size = 0
    
    # æŒ‰LRUé¡ºåºæ·˜æ±°
    while evicted_size < size:
        node = heapq.heappop(leave_nodes)  # è·å–æœ€ä¹…æœªè®¿é—®èŠ‚ç‚¹
        assert node.ref_count == 0 and node.is_leaf() and not node.is_root()
        
        evicted_size += node.length
        evicted_indices.append(node.value)
        self.evictable_size -= node.length
        
        # ä»çˆ¶èŠ‚ç‚¹ç§»é™¤å¼•ç”¨
        parent = node.parent
        del parent.children[int(node._key[0].item())]
        
        # å¦‚æœçˆ¶èŠ‚ç‚¹å˜ä¸ºå¶å­ä¸”æ— å¼•ç”¨ï¼ŒåŠ å…¥æ·˜æ±°å€™é€‰
        if parent.is_leaf() and parent.ref_count == 0:
            heapq.heappush(leave_nodes, parent)
    
    return torch.cat(evicted_indices)
```

#### æ·˜æ±°ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **LRU** | ç®€å•é«˜æ•ˆï¼Œå±€éƒ¨æ€§å¥½ | å¯èƒ½æ·˜æ±°çƒ­ç‚¹æ•°æ® | ä¸€èˆ¬ç¼“å­˜ç³»ç»Ÿ |
| **LFU** | ä¿æŠ¤é¢‘ç¹è®¿é—®æ•°æ® | éœ€è¦é¢‘ç‡ç»Ÿè®¡å¼€é”€ | è®¿é—®æ¨¡å¼ç¨³å®š |
| **Random** | å®ç°ç®€å•ï¼Œæ— å¼€é”€ | æ·˜æ±°å¯èƒ½ä¸åˆç† | å†…å­˜ç´§å¼ æ—¶ |

### 3. ç¼“å­˜æ’å…¥æœºåˆ¶

#### æ–°å‰ç¼€æ’å…¥

```python
def insert_prefix(self, input_ids: torch.Tensor, indices: torch.Tensor) -> int:
    """æ’å…¥æ–°å‰ç¼€åˆ°ç¼“å­˜"""
    
    node, prefix_len = self._walk(input_ids)
    assert prefix_len <= len(input_ids)
    
    # åªæ’å…¥æœªåŒ¹é…çš„éƒ¨åˆ†
    if prefix_len < len(input_ids):
        new_node = RadixTreeNode()
        new_node.set_key_value(input_ids[prefix_len:], indices[prefix_len:])
        new_node.set_parent(node)
        self.evictable_size += new_node.length
    
    return prefix_len
```

## æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

### 1. å†…å­˜å¸ƒå±€ä¼˜åŒ–

#### é¡µé¢ä¼˜å…ˆå¸ƒå±€

```python
case KVCacheLayout.PageFirst:
    # é¡µé¢è¿ç»­å­˜å‚¨ï¼Œé€‚åˆé¡µé¢ç®¡ç†
    kv_buffer = torch.empty((2, num_pages, num_layers, local_kv_heads, head_dim))
    kv_buffer = kv_buffer.permute(0, 2, 1, 3, 4)  # è°ƒæ•´ç»´åº¦é¡ºåº
```

**ä¼˜åŠ¿**ï¼š
- é¡µé¢å†…æ•°æ®è¿ç»­ï¼Œç¼“å­˜å±€éƒ¨æ€§å¥½
- é€‚åˆæŒ‰é¡µé¢ç®¡ç†ç¼“å­˜ç”Ÿå‘½å‘¨æœŸ
- å‡å°‘å†…å­˜ç¢ç‰‡

#### å±‚ä¼˜å…ˆå¸ƒå±€

```python
case KVCacheLayout.LayerFirst:
    # å±‚è¿ç»­å­˜å‚¨ï¼Œé€‚åˆå±‚å¹¶è¡Œ
    kv_buffer = torch.empty((2, num_layers, num_pages, local_kv_heads, head_dim))
```

**ä¼˜åŠ¿**ï¼š
- åŒå±‚æ•°æ®è¿ç»­ï¼Œé€‚åˆå±‚å¹¶è¡Œè®¡ç®—
- å‡å°‘è·¨å±‚å†…å­˜è®¿é—®
- ä¼˜åŒ–æ³¨æ„åŠ›è®¡ç®—

### 2. å†…æ ¸çº§ä¼˜åŒ–

#### JITç¼–è¯‘ä¼˜åŒ–

```python
@lru_cache(maxsize=None)
def _jit_store_module(element_size: int, config: KernelConfig) -> Module:
    """ç¼“å­˜å­˜å‚¨å†…æ ¸çš„JITç¼–è¯‘"""
    
    args = make_cpp_args(element_size, *config)
    return load_jit(
        "store",
        *args,
        cuda_files=["store.cu"],  # CUDAå†…æ ¸æºç 
        cuda_wrappers=[("launch", f"StoreKernel<{args}>::run")],
    )
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š
- è¿è¡Œæ—¶ç¼–è¯‘ä¼˜åŒ–ç‰¹å®šç¡¬ä»¶
- å†…è”å‡½æ•°è°ƒç”¨å‡å°‘å¼€é”€
- å¯„å­˜å™¨åˆ†é…ä¼˜åŒ–

### 3. å†…å­˜è®¿é—®ä¼˜åŒ–

#### è¿ç»­å†…å­˜è®¿é—®

```python
# å±•å¹³ç¼“å­˜ä»¥æ”¯æŒè¿ç»­è®¿é—®
num_tokens = k_cache.shape[0]
k_cache = k_cache.view(num_tokens, -1)
v_cache = v_cache.view(num_tokens, -1)
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š
- å‡å°‘å†…å­˜è®¿é—®æ¬¡æ•°
- æé«˜ç¼“å­˜å‘½ä¸­ç‡
- æ”¯æŒå‘é‡åŒ–æ“ä½œ

## ç¼“å­˜ç­–ç•¥å¯¹æ¯”

### 1. Radix vs Naiveç¼“å­˜ç®¡ç†å™¨

#### Naiveç¼“å­˜ç®¡ç†å™¨ï¼ˆåŸºç¡€å®ç°ï¼‰

```python
class NaiveCacheManager(BaseCacheManager):
    """ç®€å•ç¼“å­˜ç®¡ç†å™¨ï¼Œæ— å¤ç”¨ä¼˜åŒ–"""
    
    def match_prefix(self, input_ids: torch.Tensor) -> Tuple[NaiveCacheHandle, torch.Tensor]:
        _ = input_ids  # å¿½ç•¥è¾“å…¥ï¼Œå§‹ç»ˆè¿”å›ç©ºåŒ¹é…
        return NaiveCacheHandle(0), self.empty_tensor
    
    def evict(self, size: int) -> torch.Tensor:
        if size == 0:
            return self.empty_tensor
        raise NotImplementedError("NaiveCacheManager does not support eviction.")
```

#### æ€§èƒ½å¯¹æ¯”åˆ†æ

| ç‰¹æ€§ | Radixç¼“å­˜ç®¡ç†å™¨ | Naiveç¼“å­˜ç®¡ç†å™¨ |
|------|----------------|----------------|
| **ç¼“å­˜å¤ç”¨** | âœ… æ”¯æŒå‰ç¼€åŒ¹é…å’Œå¤ç”¨ | âŒ æ— å¤ç”¨æœºåˆ¶ |
| **å†…å­˜æ•ˆç‡** | âœ… é«˜ï¼Œå…±äº«å‰ç¼€èŠ‚çœå†…å­˜ | âŒ ä½ï¼Œé‡å¤å­˜å‚¨ç›¸åŒå‰ç¼€ |
| **è®¡ç®—æ•ˆç‡** | âœ… é«˜ï¼Œé¿å…é‡å¤è®¡ç®— | âŒ ä½ï¼Œé‡å¤è®¡ç®—ç›¸åŒå‰ç¼€ |
| **å®ç°å¤æ‚åº¦** | âŒ é«˜ï¼Œéœ€è¦æ ‘ç»“æ„ç®¡ç† | âœ… ä½ï¼Œç®€å•ç›´æ¥ |
| **é€‚ç”¨åœºæ™¯** | å¤šè½®å¯¹è¯ã€æ‰¹é‡ç›¸ä¼¼è¯·æ±‚ | ç®€å•æ¨ç†åœºæ™¯ |

### 2. å®é™…æ€§èƒ½æ•°æ®

æ ¹æ®å®˜æ–¹åŸºå‡†æµ‹è¯•ï¼ŒRadixç¼“å­˜ç›¸æ¯”Naiveç¼“å­˜ï¼š
- **å†…å­˜ä½¿ç”¨**ï¼šå‡å°‘30-50%ï¼ˆå…±äº«å‰ç¼€ï¼‰
- **ååé‡**ï¼šæå‡20-40%ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
- **å“åº”æ—¶é—´**ï¼šé™ä½15-30%ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰

## æœ¬ç« æ€»ç»“

æœ¬ç« è¯¦ç»†åˆ†æäº†Mini-SGLangçš„KVç¼“å­˜ç®¡ç†ç³»ç»Ÿï¼š

### ç¼“å­˜ç³»ç»Ÿæ¶æ„æ€»è§ˆ

```mermaid
graph TB
    subgraph ç¼“å­˜ç®¡ç†å±‚
        CM[CacheManager] --> RCM[RadixCacheManager]
        CM --> NCM[NaiveCacheManager]
    end
    
    subgraph Radixæ ‘ç»“æ„
        RCM --> RT[RadixTree]
        RT --> RN[RadixTreeNode]
        RN --> RC[RefCount]
        RN --> TS[Timestamp]
    end
    
    subgraph å­˜å‚¨å±‚
        KC[MHAKVCache] --> KB[K Buffer]
        KC --> VB[V Buffer]
    end
    
    subgraph å†…æ ¸ä¼˜åŒ–
        KC --> SK[Store Kernel]
        SK --> JIT[JITç¼–è¯‘]
    end
```

### æ ¸å¿ƒç»„ä»¶åŠŸèƒ½å¯¹æ¯”

| ç»„ä»¶ | åŠŸèƒ½ | å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ |
|------|------|--------|----------|
| **RadixCacheManager** | å‰ç¼€åŒ¹é…ã€ç¼“å­˜å¤ç”¨ | O(n) | å¤šè½®å¯¹è¯ã€ç›¸ä¼¼è¯·æ±‚ |
| **NaiveCacheManager** | ç®€å•åˆ†é…ã€æ— å¤ç”¨ | O(1) | ç®€å•æ¨ç†åœºæ™¯ |
| **MHAKVCache** | KVå­˜å‚¨ã€å†…å­˜ç®¡ç† | O(1) | é€šç”¨å­˜å‚¨ |
| **RadixTreeNode** | å‰ç¼€è¡¨ç¤ºã€å­èŠ‚ç‚¹ç®¡ç† | O(k) | æ ‘ç»“æ„ç»´æŠ¤ |

### å…³é”®ç®—æ³•å¤æ‚åº¦

| æ“ä½œ | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ |
|------|-----------|-----------|
| å‰ç¼€åŒ¹é… | O(n) | O(1) |
| ç¼“å­˜æ’å…¥ | O(n) | O(n) |
| ç¼“å­˜æ·˜æ±° | O(k log k) | O(k) |
| å¼•ç”¨è®¡æ•°æ›´æ–° | O(d) | O(1) |

> n = åºåˆ—é•¿åº¦ï¼Œk = æ·˜æ±°èŠ‚ç‚¹æ•°ï¼Œd = æ ‘æ·±åº¦

---

**ä¸‹ä¸€ç« é¢„å‘Š**ï¼šç¬¬å…­ç« å°†æ·±å…¥åˆ†æé«˜æ€§èƒ½å†…æ ¸ä¸CUDAä¼˜åŒ–æŠ€æœ¯ï¼Œè¿™æ˜¯å®ç°æè‡´æ€§èƒ½çš„å…³é”®ç»„ä»¶ã€‚

---

**æŠ€æœ¯è¦ç‚¹å›é¡¾**ï¼š
- Radixæ ‘é€šè¿‡å‰ç¼€åŒ¹é…å®ç°ç¼“å­˜å¤ç”¨
- å¼•ç”¨è®¡æ•°æœºåˆ¶ç¡®ä¿ç¼“å­˜è®¿é—®å®‰å…¨
- LRUæ·˜æ±°ç­–ç•¥ç®¡ç†ç¼“å­˜ç”Ÿå‘½å‘¨æœŸ
- JITç¼–è¯‘ä¼˜åŒ–æå‡å†…æ ¸æ‰§è¡Œæ•ˆç‡
- å†…å­˜å¸ƒå±€é€‰æ‹©å½±å“ç¼“å­˜è®¿é—®æ€§èƒ½